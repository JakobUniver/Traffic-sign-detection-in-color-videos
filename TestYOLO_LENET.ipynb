{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakobUniver/Traffic-sign-detection-in-color-videos/blob/main/TestYOLO_LENET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JakobUniver/Traffic-sign-detection-in-color-videos.git -q"
      ],
      "metadata": {
        "id": "mqOHM2PLa3Jo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git -q"
      ],
      "metadata": {
        "id": "9XEzaoeNa7Tw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WfYngWH_t72n"
      },
      "outputs": [],
      "source": [
        "# Yolo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Lenet Imports\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2_Dgb1WQeGZu",
        "outputId": "5ab7db3a-39a1-4537-a818-f2c92640b075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLO part"
      ],
      "metadata": {
        "id": "L9RiMWJNuucu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yolo_model = torch.hub.load('yolov7', 'custom', 'Traffic-sign-detection-in-color-videos/model.pt', source='local') "
      ],
      "metadata": {
        "id": "quEJJA4Guxpx",
        "outputId": "22afc992-3a30-4f98-d794-4f0ff235bbaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m jedi>=0.10 not found and is required by YOLOR, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/yolov7/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Adding autoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lenet part"
      ],
      "metadata": {
        "id": "olYg3yZIbDBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_shape=(64,64)"
      ],
      "metadata": {
        "id": "ZaFj3nLUbSYh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = keras.models.load_model('Traffic-sign-detection-in-color-videos/lenet_model')"
      ],
      "metadata": {
        "id": "nzr5AV3VYroa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = pd.read_csv('Traffic-sign-detection-in-color-videos/lenet_classes.csv')\n",
        "classes = classes.columns[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ib-OfYZUuoM6",
        "outputId": "381ae24e-7323-4227-b2a8-e02bf7db09d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Turn right ahead'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined model"
      ],
      "metadata": {
        "id": "3KqBdSlKbM3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cap = cv2.VideoCapture('traffic-sign-to-test.mp4')\n",
        "cap = cv2.VideoCapture('drive/MyDrive/DashCamTestShort.mp4')\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "   \n",
        "size = (frame_width, frame_height)\n",
        "result = cv2.VideoWriter('resultDashCamTest.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
        " \n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        " \n",
        "while(cap.isOpened()):\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    \n",
        "    detected = Yolo_model(frame)\n",
        "    new_frame = frame.copy()\n",
        "    for i, d in detected.pandas().xyxy[0].iterrows():\n",
        "\n",
        "      crop = frame[int(d.ymin):int(np.ceil(d.ymax)), int(d.xmin):int(np.ceil(d.xmax))]\n",
        "      new_crop = cv2.resize(crop, crop_shape, interpolation=cv2.INTER_AREA)\n",
        "      pred = lenet_model.predict(np.array([new_crop]), verbose=0).argmax()\n",
        "      cv2.rectangle(new_frame, (int(d.xmin), int(d.ymin)), (int(np.ceil(d.xmax)), int(np.ceil(d.ymax))), (255,0,0), 2)\n",
        "      new_frame = cv2.putText(new_frame, classes[pred], (int(d.xmin), int(d.ymin)),\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
        "      \n",
        "      \"\"\"\n",
        "      if len(crop) > 0:\n",
        "        cv2_imshow(crop)\n",
        "      \"\"\"\n",
        "      \n",
        "\n",
        "    result.write(new_frame)\n",
        "    cv2.waitKey(1) & 0xff\n",
        " \n",
        "  else: \n",
        "    break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "result.release()"
      ],
      "metadata": {
        "id": "otB6t1wbu_r5"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}
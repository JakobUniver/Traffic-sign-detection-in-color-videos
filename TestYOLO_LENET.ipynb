{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSZaRT13zu1M+QC7k8Yudq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakobUniver/Traffic-sign-detection-in-color-videos/blob/main/TestYOLO_LENET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfYngWH_t72n"
      },
      "outputs": [],
      "source": [
        "# Yolo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Lenet Imports\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crop_shape=(64,64)"
      ],
      "metadata": {
        "id": "QhNlcJt4ul4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = None"
      ],
      "metadata": {
        "id": "_6_qaAyZzEBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLO part"
      ],
      "metadata": {
        "id": "L9RiMWJNuucu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JakobUniver/Traffic-sign-detection-in-color-videos.git -q"
      ],
      "metadata": {
        "id": "Af_3QgExuwfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Yolo_model = torch.hub.load('yolov7', 'custom', 'Traffic-sign-detection-in-color-videos/model.pt', source='local') "
      ],
      "metadata": {
        "id": "quEJJA4Guxpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('traffic-sign-to-test.mp4')\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "   \n",
        "size = (frame_width, frame_height)\n",
        "result = cv2.VideoWriter('result.mp4', cv2.VideoWriter_fourcc(*'MP4V'),10, size)\n",
        " \n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        " \n",
        "while(cap.isOpened()):\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    \n",
        "    detected = Yolo_model(frame)\n",
        "    new_frame = frame.copy()\n",
        "    for i, d in detected.pandas().xyxy[0].iterrows():\n",
        "\n",
        "      crop = frame[int(d.ymin):int(np.ceil(d.ymax)), int(d.xmin):int(np.ceil(d.xmax))]\n",
        "      new_crop = cv2.cvtColor(cv2.resize(crop, crop_shape, interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2GRAY)\n",
        "      \n",
        "      \n",
        "      lenet_model\n",
        "      cv2.rectangle(new_frame, (int(d.xmin), int(d.ymin)), (int(np.ceil(d.xmax)), int(np.ceil(d.ymax))), (255,0,0), 2)\n",
        "      \"\"\"\n",
        "      if len(crop) > 0:\n",
        "        cv2_imshow(crop)\n",
        "      \"\"\"\n",
        "\n",
        "    result.write(new_frame)\n",
        "    cv2.waitKey(1) & 0xff\n",
        " \n",
        "  else: \n",
        "    break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "result.release()"
      ],
      "metadata": {
        "id": "otB6t1wbu_r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lenet part"
      ],
      "metadata": {
        "id": "teJWnjskuY6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes =\n",
        "img_shape = (64,64)\n",
        "y = data_df.apply(lambda row: row.values[1:num_classes+1], axis=1)"
      ],
      "metadata": {
        "id": "Vrty80QkviL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img():\n",
        "  ..."
      ],
      "metadata": {
        "id": "Wobn-t4Ov_wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MZ4talGucCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wz5bd3AvTD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_frame(frame)->list:"
      ],
      "metadata": {
        "id": "1cCsG37HvT5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}